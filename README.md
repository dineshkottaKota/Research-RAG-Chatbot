# ğŸ§  Conversational RAG System using Groq + HuggingFace Embeddings

This repository implements a **Conversational Retrieval-Augmented Generation (RAG)** system using:

- ğŸ” **HuggingFace sentence-transformer embeddings** for document encoding
- ğŸ§  **LLaMA3** (via **Groq API**) as the LLM
- ğŸ“„ **PDF-based document ingestion**
- ğŸ’¬ Context-aware **conversational question-answering**
- ğŸ§  Simulated persona: **25-year experienced researcher**
- âš™ï¸ Built using the **LangChain** framework and **FAISS** for vector search

---

## ğŸ“Œ Features

- ğŸ“š Upload your PDF and ask natural questions about it
- ğŸ’¬ Understands follow-up questions using chat history
- ğŸ§  Responds like a highly experienced domain researcher
- âš¡ Extremely fast generation using Groqâ€™s LLaMA3 backend
- âŒ No OpenAI dependency â€“ uses free HuggingFace embeddings

---

## ğŸ—ï¸ Architecture

User Query â Condense Prompt (Chat History + Follow-up)
â Standalone Question â FAISS Retriever (PDF Chunks)
â Groq LLaMA3 â Final Answer
